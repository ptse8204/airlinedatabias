{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlymO4uiA8KAbaLVSuhyqO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ptse8204/airlinedatabias/blob/main/dsc180b_converters_func.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "This modules produced in this notebook should be able to grab all the neccessary module for a smooth navigation and use of the dataset along the road"
      ],
      "metadata": {
        "id": "pCrP_Zdt8wno"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Survey -- ticket useable functions\n",
        "\n",
        "The ticket.py was updated from ticket_eda\n",
        "\n",
        "Naming convention -- not yet resolved"
      ],
      "metadata": {
        "id": "jCHNzdrxnvgv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mNZPaFInrP_",
        "outputId": "84bef32f-9460-44c9-d578-dd31df6066d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing ticket.py\n"
          ]
        }
      ],
      "source": [
        "#@title ticket.py_file\n",
        "%%writefile ticket.py\n",
        "#### this py file contains EDA functions for Ticket Datasets (2018 - 2022)\n",
        "\n",
        "# Dependency\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Joseph\n",
        "def flight_length_bar(dataset):\n",
        "  #Flight length\n",
        "  def flight_length(x):\n",
        "    if x <= 1725: #miles\n",
        "        return \"short-haul\"\n",
        "    elif x>1725 and x<=3450:\n",
        "        return \"medium-haul\"\n",
        "    else:\n",
        "        return \"long-haul\"\n",
        "\n",
        "  #adding new column to data and plotting bar chart\n",
        "  dataset[\"flight_length\"]=dataset[\"MilesFlown\"].apply(lambda x: flight_length(x))\n",
        "  lengths=dataset.groupby(\"flight_length\").count()[\"ItinID\"]\n",
        "  plt.bar(x=lengths.index,height=lengths)\n",
        "  plt.title(\"Flight Length Count\")\n",
        "\n",
        "#adjusting fare columns for inflation \n",
        "def inflation(dataset,inflation_amount):\n",
        "    #inflation amount in decimals\n",
        "    #ex: 2019 to 2022 = 14.5% ->0.145\n",
        "    dataset[\"FarePerMile\"]=dataset[\"FarePerMile\"].apply(lambda x: x + (x*inflation_amount)) \n",
        "    dataset[\"ItinFare\"]=dataset[\"ItinFare\"].apply(lambda x: x + (x*inflation_amount)) \n",
        "    return dataset\n",
        "\n",
        "\n",
        "\n",
        "### Qixi Huang\n",
        "\n",
        "### $1 in 2018 is worth $1.16 in 2022\n",
        "def adjust_inflation_2018(dataset):\n",
        "    dataset['ItinFare'] = dataset['ItinFare'].apply(lambda x: x * 1.16)\n",
        "    dataset['FarePerMile'] = dataset['FarePerMile'].apply(lambda x: x * 1.16)\n",
        "\n",
        "def Market_share_Carrier(dataset):\n",
        "    ### plot bars chart that show market share for each airlines\n",
        "    carrier_percent = dataset.RPCarrier.value_counts()\n",
        "    carrier_percent.plot.bar()\n",
        "\n",
        "def Rev_Carrier(dataset):\n",
        "    ### plot bars chart that show revenue per miles on each airlines\n",
        "    avg_rev = dataset.groupby('RPCarrier')['FarePerMile'].mean()\n",
        "    avg_rev.sort_values().plot.bar()\n",
        "\n",
        "def fare_to_dis(dataset):\n",
        "    ### bar charts that show fare per mile with respect to flight_length\n",
        "    avg_rev_dis = dataset.groupby('flight_length')['FarePerMile'].mean()\n",
        "    avg_rev_dis.plot.bar()\n",
        "\n",
        "def carrier_option_dis(dataset):\n",
        "    \n",
        "    ### returns two dictionaries that shows whats the most and least profitable option\n",
        "    ### in terms of flight length category, e.g. short hual maybe more profitable for some carriers.\n",
        "    carrier_dis_table = dataset.groupby(['RPCarrier','flight_length'])['FarePerMile'].mean()\n",
        "    \n",
        "    carrier_percent = dataset.RPCarrier.value_counts()\n",
        "    \n",
        "    profit_dis_airline = dict()\n",
        "    not_profit_dis_airline = dict()\n",
        "    \n",
        "    for i in carrier_percent.index:\n",
        "        \n",
        "        profit_dis_airline[i] = carrier_dis_table[i].idxmax()\n",
        "        not_profit_dis_airline[i] = carrier_dis_table[i].idxmin()\n",
        "        \n",
        "    return [profit_dis_airline, not_profit_dis_airline]\n",
        "\n",
        "\n",
        "# Garrick Su\n",
        "\n",
        "import cpi \n",
        "from datetime import date\n",
        "\n",
        "def inflation(row):\n",
        "    month = 1 if row[\"Quarter\"] == 1 else (3 if row[\"Quarter\"] == 2 else (6 if row[\"Quarter\"] == 3 else 9))\n",
        "    row[\"ItinFare\"] = cpi.inflate(row[\"ItinFare\"], date(row[\"Year\"], month, 1), to=date(2022, 1, 1))\n",
        "    row[\"FarePerMile\"] = cpi.inflate(row[\"FarePerMile\"], date(row[\"Year\"], month, 1), to=date(2022, 1, 1))\n",
        "    return row\n",
        "\n",
        "def convert_inflation(dataset):\n",
        "    return dataset.apply(inflation, axis=1)\n",
        "\n",
        "def clean_and_merge_race_city(L_CITY_MARKET_ID, race, dataset):\n",
        "    race = race.T\n",
        "    race.columns = race.iloc[0]\n",
        "    race = race.drop(race.index[0]).reset_index()\n",
        "    race[\"Metro Area\"] = race['index'].apply(lambda x: x[-10:] == \"Metro Area\")\n",
        "    race[\"Area Name\"] = race['index'].apply(lambda x: x[:-11])\n",
        "    race = race.merge(L_CITY_MARKET_ID, left_on=\"Area Name\", right_on=\"Description\", how='inner')\n",
        "    return race, race.merge(dataset, left_on=\"Code\", right_on=\"OriginCityMarketID\", how='inner')\n",
        "\n",
        "def lowest_and_highest_5(merged_dataset, merged_race):\n",
        "    lowest_5 = merged_dataset.groupby(\"Code\").mean()[\"ItinFare\"].sort_values().iloc[0:5].index\n",
        "    highest_5 = merged_dataset.groupby(\"Code\").mean()[\"ItinFare\"].sort_values().iloc[-5:].index\n",
        "    return race[race[\"Code\"].isin(lowest_5)], race[race[\"Code\"].isin(highest_5)]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Edwin\n",
        "## Ticket, works with combined\n",
        "\n",
        "# Drop fpm outliers\n",
        "def filter_ticket_df_outliers(ticket_df,combined):\n",
        "\treturn ticket_df[combined[\"FarePerMile\"] < ticket_df[\"FarePerMile\"].quantile(.99)]\n",
        "\n",
        "# This function return average FarePerMile per Carrier\n",
        "def avg_fpm(ticket_df):\n",
        "    ticket_df.groupby(\"RPCarrier\").mean()[\"FarePerMile\"].plot(kind=\"bar\")\n",
        "\n",
        "# This function return average FarePerMile per Carrier for Legacy Airlines\n",
        "def avg_fpm_legacy(ticket_df):\n",
        "    ticket_df.groupby(\"RPCarrier\").mean()[\"FarePerMile\"].loc[[\\\n",
        "    \"AA\", \"AS\", \"B6\", \"DL\", \"HA\", \"UA\", \"WN\"]].plot(kind=\"barh\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Survey -- coupon useable functions"
      ],
      "metadata": {
        "id": "l_Lv7H9Juut1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title coupon.py file\n",
        "%%writefile coupon.py\n",
        "# Dependency\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "### Edwin\n",
        "## Coupon, works with combined\n",
        "# This function allows filtering different classes\n",
        "# accept input of a single class\n",
        "def select_class(coupon_df, class_str):\n",
        "  return coupon_df[coupon_df['FareClass'] == class_str]\n",
        "\n",
        "# This function allows filtering only the class (X, Y)\n",
        "def econ_class(coupon_df):\n",
        "  return coupon_df[(coupon_df.FareClass == \"X\")|(coupon_df.FareClass == \"Y\")]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "wiMztTZiuw3e",
        "outputId": "0bdc4e5b-4fda-4dd5-807f-7e545afa93cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing coupon.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Survey -- combined functions"
      ],
      "metadata": {
        "id": "MQhLwZ8avVES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title other.py file\n",
        "%%writefile other.py\n",
        "\n",
        "# Dependency\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "### Edwin\n",
        "## Combined\n",
        "# This function would provide a table that grab columns\n",
        "# that we need in both sets and return a useful df\n",
        "\n",
        "# Essential this table would combine the 2 tables with only useful columns\n",
        "\n",
        "def gen_ticket_coupon(ticket_df, coupon_df):\n",
        "  ticket_df_reduced = ticket_df[[\"ItinID\", \"Coupons\", 'Year', 'Quarter', \n",
        "                                 'Origin', 'OriginCityMarketID', 'OriginState',\n",
        "                                 'RoundTrip', 'OnLine', 'DollarCred', 'FarePerMile',\n",
        "                                  'RPCarrier', 'Passengers', 'ItinFare', 'BulkFare'\n",
        "                                  , 'MilesFlown', 'ItinGeoType']]\n",
        "  del ticket_df\n",
        "  coupon_df_reduced = coupon_df[['ItinID','SeqNum', 'Coupons', 'Year', \n",
        "                                 'Quarter', 'DestCityMarketID', 'Dest', \n",
        "                                 'DestState', 'CouponGeoType', 'FareClass']]\n",
        "  del coupon_df\n",
        "  max_gp = coupon_df_reduced[[\"SeqNum\", \"ItinID\"]].groupby(\"ItinID\").max().reset_index()\n",
        "  coupon_df_filter = coupon_df_reduced.merge(max_gp, on=[\"ItinID\",\t\"SeqNum\"])\n",
        "  return ticket_df_reduced.merge(coupon_df_filter, on=['ItinID', 'Year', 'Quarter'])\n",
        "\n",
        "\n",
        "### Edwin\n",
        "\n",
        "## Connecting census dataset\n",
        "# Reading Census City Data\n",
        "# Depreciated\n",
        "def read_cen_data(path):\n",
        "  census_city_code = pd.read_csv(path)\n",
        "  census_city_code[\"median_income\"] = census_city_code[\"11\"].str.replace(\",\", \"\").astype(\"int\")\n",
        "  return census_city_code\n",
        "\n",
        "# Just a histogram for median income\n",
        "def us_city_median_income_plot(census_df):\n",
        "  census_df.median_income.plot(kind=\"hist\")\n",
        "\n",
        "### Edwin\n",
        "## Census EDA with Airline Data, Prereq: Combined, Census\n",
        "\n",
        "# This shows the data statistics of city areas that has \n",
        "# median income in the bottom 25 percentile\n",
        "def bottom_25_data(combined, census_df):\n",
        "    bot_25_median = census_df.median_income.quantile(.25)\n",
        "    bottom_25_origins = combined[[\"FarePerMile\", \"RPCarrier\", \"OriginCityMarketID\", \n",
        "                                  \"MilesFlown\", \"SeqNum\"]].merge(\n",
        "      census_df[census_df.median_income <= bot_25_median][[\"Code\", \"median_income\"]], \n",
        "      left_on = \"OriginCityMarketID\", right_on=\"Code\")\n",
        "    bottom_25_dest = combined[[\"FarePerMile\", \"RPCarrier\", \"DestCityMarketID\", \n",
        "                               \"MilesFlown\", \"SeqNum\"]].merge(\n",
        "      census_df[census_df.median_income <= bot_25_median][[\"Code\", \"median_income\"]], \n",
        "      left_on = \"DestCityMarketID\", right_on=\"Code\")\n",
        "    print(\"Flights originate city areas that has median income in the bottom 25 percentile\")\n",
        "    print(\"Mean of FarePerMile : \", bottom_25_origins.FarePerMile.mean())\n",
        "    print(\"Mean of MilesFlown : \", bottom_25_origins.MilesFlown.mean())\n",
        "    print(\"Mean of Average Segments:\", bottom_25_origins.SeqNum.mean())\n",
        "    print(\"FarePerMile by carrier:\")\n",
        "    bottom_25_origins[[\"FarePerMile\", \"RPCarrier\"]].groupby(\"RPCarrier\").mean()[\"FarePerMile\"].plot(kind=\"bar\")\n",
        "    plt.show()\n",
        "    print(\"FarePerMile Distribution:\")\n",
        "    bottom_25_origins.FarePerMile.hist()\n",
        "    plt.show()\n",
        "    print(\"Flights destination is city areas that has median income in the bottom 25 percentile\")\n",
        "    print(\"Mean of FarePerMile : \", bottom_25_dest.FarePerMile.mean())\n",
        "    print(\"Mean of MilesFlown : \", bottom_25_dest.MilesFlown.mean())\n",
        "    print(\"Mean of Average Segments:\", bottom_25_dest.SeqNum.mean())\n",
        "    print(\"FarePerMile by carrier:\")\n",
        "    bottom_25_dest[[\"FarePerMile\", \"RPCarrier\"]].groupby(\"RPCarrier\").mean()[\"FarePerMile\"].plot(kind=\"bar\")\n",
        "    plt.show()\n",
        "    print(\"FarePerMile Distribution:\")\n",
        "    bottom_25_dest.FarePerMile.hist()\n",
        "    plt.show()\n",
        "\n",
        "# This shows the data statistics of city areas that has \n",
        "# median income in the upper 25 percentile\n",
        "def upper_25_data(combined, census_df):\n",
        "    bot_25_median = census_df.median_income.quantile(.75)\n",
        "    upper_25_origins = combined[[\"FarePerMile\", \"RPCarrier\", \"OriginCityMarketID\", \n",
        "                                  \"MilesFlown\", \"SeqNum\"]].merge(\n",
        "      census_df[census_df.median_income >= bot_25_median][[\"Code\", \"median_income\"]], \n",
        "      left_on = \"OriginCityMarketID\", right_on=\"Code\")\n",
        "    upper_25_dest = combined[[\"FarePerMile\", \"RPCarrier\", \"DestCityMarketID\", \n",
        "                               \"MilesFlown\", \"SeqNum\"]].merge(\n",
        "      census_df[census_df.median_income >= bot_25_median][[\"Code\", \"median_income\"]], \n",
        "      left_on = \"DestCityMarketID\", right_on=\"Code\")\n",
        "    print(\"Flights originate city areas that has median income in the upper 25 percentile\")\n",
        "    print(\"Mean of FarePerMile : \", upper_25_origins.FarePerMile.mean())\n",
        "    print(\"Mean of MilesFlown : \", upper_25_origins.MilesFlown.mean())\n",
        "    print(\"Mean of Average Segments:\", upper_25_origins.SeqNum.mean())\n",
        "    print(\"FarePerMile by carrier:\")\n",
        "    upper_25_origins[[\"FarePerMile\", \"RPCarrier\"]].groupby(\"RPCarrier\").mean()[\"FarePerMile\"].plot(kind=\"bar\")\n",
        "    plt.show()\n",
        "    print(\"FarePerMile Distribution:\")\n",
        "    upper_25_origins.FarePerMile.hist()\n",
        "    plt.show()\n",
        "    print(\"Flights destination is city areas that has median income in the upper 25 percentile\")\n",
        "    print(\"Mean of FarePerMile : \", upper_25_dest.FarePerMile.mean())\n",
        "    print(\"Mean of MilesFlown : \", upper_25_dest.MilesFlown.mean())\n",
        "    print(\"Mean of Average Segments:\", upper_25_dest.SeqNum.mean())\n",
        "    print(\"FarePerMile by carrier:\")\n",
        "    upper_25_dest[[\"FarePerMile\", \"RPCarrier\"]].groupby(\"RPCarrier\").mean()[\"FarePerMile\"].plot(kind=\"bar\")\n",
        "    plt.show()\n",
        "    print(\"FarePerMile Distribution:\")\n",
        "    upper_25_dest.FarePerMile.hist()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# This shows the flight statistics of city areas that has \n",
        "# with upper and lower 25th percentile as orgin and dest\n",
        "# and vice-versa\n",
        "def lower_and_upper_data(combined, census_df):\n",
        "    bot_25_median = census_df.median_income.quantile(.25)\n",
        "    up_25_median = census_df.median_income.quantile(.75)\n",
        "    origins = combined[[\"FarePerMile\", \"RPCarrier\", \"OriginCityMarketID\", \n",
        "                                  \"DestCityMarketID\", \"MilesFlown\", \"SeqNum\"]].merge(\n",
        "      census_df[census_df.median_income <= bot_25_median][[\"Code\", \"median_income\"]], \n",
        "      left_on = \"OriginCityMarketID\", right_on=\"Code\")\n",
        "    origin_dest = origins.merge(\n",
        "      census_df[census_df.median_income >= up_25_median][[\"Code\", \"median_income\"]], \n",
        "      left_on = \"DestCityMarketID\", right_on=\"Code\")\n",
        "    print(\"Flights originate bottom 25 to upper 25\")\n",
        "    print(\"Mean of FarePerMile : \", origin_dest.FarePerMile.mean())\n",
        "    print(\"Mean of MilesFlown : \", origin_dest.MilesFlown.mean())\n",
        "    print(\"Mean of Average Segments:\", origin_dest.SeqNum.mean())\n",
        "    print(\"FarePerMile by carrier:\")\n",
        "    origin_dest[[\"FarePerMile\", \"RPCarrier\"]].groupby(\"RPCarrier\").mean()[\"FarePerMile\"].plot(kind=\"bar\")\n",
        "    plt.show()\n",
        "    print(\"FarePerMile Distribution:\")\n",
        "    origin_dest.FarePerMile.hist()\n",
        "    plt.show()\n",
        "    origins = combined[[\"FarePerMile\", \"RPCarrier\", \"OriginCityMarketID\", \n",
        "                                  \"DestCityMarketID\", \"MilesFlown\", \"SeqNum\"]].merge(\n",
        "      census_df[census_df.median_income >= up_25_median][[\"Code\", \"median_income\"]], \n",
        "      left_on = \"OriginCityMarketID\", right_on=\"Code\")\n",
        "    origin_dest = origins.merge(\n",
        "      census_df[census_df.median_income <= bot_25_median][[\"Code\", \"median_income\"]], \n",
        "      left_on = \"DestCityMarketID\", right_on=\"Code\")\n",
        "    print(\"Flights originate upper 25 to bottom 25\")\n",
        "    print(\"Mean of FarePerMile : \", origin_dest.FarePerMile.mean())\n",
        "    print(\"Mean of MilesFlown : \", origin_dest.MilesFlown.mean())\n",
        "    print(\"Mean of Average Segments:\", origin_dest.SeqNum.mean())\n",
        "    print(\"FarePerMile by carrier:\")\n",
        "    origin_dest[[\"FarePerMile\", \"RPCarrier\"]].groupby(\"RPCarrier\").mean()[\"FarePerMile\"].plot(kind=\"bar\")\n",
        "    plt.show()\n",
        "    print(\"FarePerMile Distribution:\")\n",
        "    origin_dest.FarePerMile.hist()\n",
        "    plt.show()\n",
        "\n",
        "# This shows the flight statistics of city areas that has \n",
        "# with upper25 as both orgin and dest\n",
        "# and lower as both orgin and dest\n",
        "def double_low_high(combined, census_df):\n",
        "    bot_25_median = census_df.median_income.quantile(.25)\n",
        "    up_25_median = census_df.median_income.quantile(.75)\n",
        "    origins = combined[[\"FarePerMile\", \"RPCarrier\", \"OriginCityMarketID\", \n",
        "                                  \"DestCityMarketID\", \"MilesFlown\", \"SeqNum\"]].merge(\n",
        "      census_df[census_df.median_income <= bot_25_median][[\"Code\", \"median_income\"]], \n",
        "      left_on = \"OriginCityMarketID\", right_on=\"Code\")\n",
        "    origin_dest = origins.merge(\n",
        "      census_df[census_df.median_income <= bot_25_median][[\"Code\", \"median_income\"]], \n",
        "      left_on = \"DestCityMarketID\", right_on=\"Code\")\n",
        "    print(\"Flights originate and destin for bottom 25\")\n",
        "    print(\"Mean of FarePerMile : \", origin_dest.FarePerMile.mean())\n",
        "    print(\"Mean of MilesFlown : \", origin_dest.MilesFlown.mean())\n",
        "    print(\"Mean of Average Segments:\", origin_dest.SeqNum.mean())\n",
        "    print(\"FarePerMile by carrier:\")\n",
        "    origin_dest[[\"FarePerMile\", \"RPCarrier\"]].groupby(\"RPCarrier\").mean()[\"FarePerMile\"].plot(kind=\"bar\")\n",
        "    plt.show()\n",
        "    print(\"FarePerMile Distribution:\")\n",
        "    origin_dest.FarePerMile.hist()\n",
        "    plt.show()\n",
        "    origins = combined[[\"FarePerMile\", \"RPCarrier\", \"OriginCityMarketID\", \n",
        "                                  \"DestCityMarketID\", \"MilesFlown\", \"SeqNum\"]].merge(\n",
        "      census_df[census_df.median_income >= up_25_median][[\"Code\", \"median_income\"]], \n",
        "      left_on = \"OriginCityMarketID\", right_on=\"Code\")\n",
        "    origin_dest = origins.merge(\n",
        "      census_df[census_df.median_income >= up_25_median][[\"Code\", \"median_income\"]], \n",
        "      left_on = \"DestCityMarketID\", right_on=\"Code\")\n",
        "    print(\"Flights originate and destin for upper 25\")\n",
        "    print(\"Mean of FarePerMile : \", origin_dest.FarePerMile.mean())\n",
        "    print(\"Mean of MilesFlown : \", origin_dest.MilesFlown.mean())\n",
        "    print(\"Mean of Average Segments:\", origin_dest.SeqNum.mean())\n",
        "    print(\"FarePerMile by carrier:\")\n",
        "    origin_dest[[\"FarePerMile\", \"RPCarrier\"]].groupby(\"RPCarrier\").mean()[\"FarePerMile\"].plot(kind=\"bar\")\n",
        "    plt.show()\n",
        "    print(\"FarePerMile Distribution:\")\n",
        "    origin_dest.FarePerMile.hist()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-_xaDUmvbHY",
        "outputId": "4ae2d5dc-f217-4006-9fd0-5b83723b4bd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing other.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# T-100 Real Flight and Passenger count data\n",
        "Useful for getting load factors, and estimating real revenue"
      ],
      "metadata": {
        "id": "M7VeS4pSw5tC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title T-100 file\n",
        "%%writefile t100.py\n",
        "\n",
        "## T-100\n",
        "# Please only use the domestic segment data for this module\n",
        "\n",
        "# dependency\n",
        "import pandas as pd\n",
        "\n",
        "# would return only with flights that are schedule for passenger\n",
        "def import_T100(path):\n",
        "  segment = pd.read_csv(path)\n",
        "  print(\"Successfully imported!\")\n",
        "  # filtering with passenger class, passenger aircraft, and flights that never run\n",
        "  passenger = segment[(segment.CLASS == \"F\") & (segment[\"AIRCRAFT_CONFIG\"] == 1) & segment[\"DEPARTURES_PERFORMED\"] != 0]\n",
        "  return passenger\n",
        "\n",
        "# A preset of useful columns\n",
        "def useful_cols(passenger):\n",
        "  return passenger[[\"DEPARTURES_PERFORMED\", \"CARRIER\", 'UNIQUE_CARRIER_NAME','SEATS','PASSENGERS'\n",
        "                    , 'DISTANCE', 'RAMP_TO_RAMP', 'CARRIER_GROUP_NEW', 'ORIGIN_CITY_MARKET_ID', \n",
        "                'ORIGIN', 'DEST_CITY_MARKET_ID', 'DEST', 'YEAR', 'QUARTER', 'MONTH', 'DISTANCE_GROUP']]\n",
        "\n",
        "# Grabbing load factor value series\n",
        "# note that the orginal dataset passenger and load count a summarized with the same \"departure\"\n",
        "# this means that if depart_per = 100, passenger = 10000, per flight passenger avg is 100\n",
        "def gen_load_factor_series(t100_df):\n",
        "  return t100_df.PASSENGERS / t100_df.SEATS / t100_df.DEPARTURES_PERFORMED\n",
        "\n",
        "# t-100 segment should only be merging with coupon as it is per segement\n",
        "# note that t-100 is annual data and coupon is better be use as a quarter data\n",
        "# due to its sear size\n",
        "# note that this would only match with market city pair and give the coupon dataset\n",
        "# the load factor and departures performed \n",
        "# the function would run and grab the load_factor variable and should be \n",
        "# able to run with load_factor var in with no error as well\n",
        "def matching_coupon(t100_df, coupon_df):\n",
        "  t100_df_load = t100_df.copy()\n",
        "  t100_df_load[\"LOAD_FACTOR\"] = gen_load_factor_series(t100_df_load)\n",
        "  t_100_grouped = t_100_df.groupby(['YEAR', 'QUARTER', 'CARRIER','ORIGIN_CITY_MARKET_ID', \n",
        "                                    'DEST_CITY_MARKET_ID'])\n",
        "  # this is the city-pair load factor given on a specific carrier\n",
        "  t_100_grouped_mean = t_100_grouped.mean()[[\"LOAD_FACTOR\"]]\n",
        "  # The pass_tran and set_tran means given year, quarter and city-pair the total amount of such available\n",
        "  t_100_grouped_sum = t_100_grouped.sum()[[\"PASSENGERS\", 'SEATS', \n",
        "                                           \"DEPARTURES_PERFORMED\"]].rename(\n",
        "                                               columns={\"PASSENGERS\": \"PASSENGERS_TRANS\", 'SEATS': \"SEATS_TRANS\"})\n",
        "  t_100_stat = t_100_grouped_mean.join(t_100_grouped_sum).reset_index()\n",
        "  return coupon_df.merge(t_100_stat, how=\"left\", on = ['YEAR', 'QUARTER', 'CARRIER','ORIGIN_CITY_MARKET_ID', \n",
        "                                    'DEST_CITY_MARKET_ID'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "m3Bn-q2M7o7W",
        "outputId": "079b3a50-b3cb-4338-a1db-2abfd3703da2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing t100.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uw1Kwx1yHF6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ad17094-be2d-4103-ad91-e7ee2f7ff485"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing manager.py\n"
          ]
        }
      ],
      "source": [
        "#@title Passing functions for All coupon and ticket\n",
        "\n",
        "%%writefile manager.py\n",
        "\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "from other import gen_ticket_coupon\n",
        "\n",
        "# This function allow for easy extraction of coupon zip\n",
        "def load_coupon(path, year, quarter):\n",
        "  with zipfile.ZipFile(\n",
        "    \"{path_f}/Origin_and_Destination_Survey_DB1BCoupon_{year_f}_{quarter_f}.zip\".format(\n",
        "        path_f = path, year_f = year, quarter_f = quarter),\"r\") as zip_ref:\n",
        "    df_path = zip_ref.extract([i for i in zip_ref.namelist() if \".csv\" in i][0])\n",
        "  return df_path # Path of result file\n",
        "\n",
        "# This function allow for easy access of coupon dataframe\n",
        "def load_coupon_df(path, year, quarter):\n",
        "  return pd.read_csv(load_coupon(path, year, quarter))\n",
        "\n",
        "# This function allow for easy extraction of ticket zip\n",
        "def load_ticket(path, year, quarter):\n",
        "  with zipfile.ZipFile(\n",
        "    \"{path_f}/Origin_and_Destination_Survey_DB1BTicket_{year_f}_{quarter_f}.zip\".format(\n",
        "        path_f = path, year_f = year, quarter_f = quarter),\"r\") as zip_ref:\n",
        "    df_path = zip_ref.extract([i for i in zip_ref.namelist() if \".csv\" in i][0])\n",
        "  return df_path # Path of result file\n",
        "\n",
        "# This function allow for easy access of coupon dataframe\n",
        "def load_ticket_df(path, year, quarter):\n",
        "  return pd.read_csv(load_ticket(path, year, quarter))\n",
        "\n",
        "# zip -- boolean --True = is a zip path --False = is a .csv path\n",
        "# feed func_arg with any variables to succesfully to run your function\n",
        "def run_result_among_ticket(year_start, quarter_start, year_end, quarter_end, \n",
        "                            path, zip, function, *func_arg):\n",
        "  result_storage = []\n",
        "  for y in range(year_start, year_end + 1):\n",
        "    q_loader_s = 1\n",
        "    q_loader_e = 5\n",
        "    if y == year_start:\n",
        "      q_loader_s = quarter_start\n",
        "    elif y == year_end:\n",
        "      q_loader_e = quarter_end + 1\n",
        "    for q in range(q_loader_s, q_loader_e):\n",
        "      if zip:\n",
        "        curr_df = load_ticket_df(path, y, q)\n",
        "      else:\n",
        "        curr_df = pd.read_csv(\n",
        "              \"{path_f}/Origin_and_Destination_Survey_DB1BTicket_{year_f}_{quarter_f}.{file_type}\"\n",
        "              .format(path_f = path, year_f = y, quarter_f = q, file_type = \"zip\" if zip else \"csv\"))\n",
        "      result_storage.append(function(curr_df, *func_arg))\n",
        "      del curr_df\n",
        "  return result_storage\n",
        "\n",
        "def run_result_among_coupon(year_start, quarter_start, year_end, quarter_end, \n",
        "                            path, zip, function, *func_arg):\n",
        "  result_storage = []\n",
        "  for y in range(year_start, year_end + 1):\n",
        "    q_loader_s = 1\n",
        "    q_loader_e = 5\n",
        "    if y == year_start:\n",
        "      q_loader_s = quarter_start\n",
        "    elif y == year_end:\n",
        "      q_loader_e = quarter_end + 1\n",
        "    for q in range(q_loader_s, q_loader_e):\n",
        "      if zip:\n",
        "        curr_df = load_coupon_df(path, y, q)\n",
        "      else:\n",
        "        curr_df = pd.read_csv(\n",
        "              \"{path_f}/Origin_and_Destination_Survey_DB1BCoupon_{year_f}_{quarter_f}.{file_type}\"\n",
        "              .format(path_f = path, year_f = y, quarter_f = q, file_type = \"zip\" if zip else \"csv\"))\n",
        "      result_storage.append(function(curr_df, *func_arg))\n",
        "      del curr_df\n",
        "  return result_storage\n",
        "\n",
        "def run_result_among_combined(\n",
        "    year_start, quarter_start, year_end, quarter_end,\n",
        "    ticket_path, coupon_path, zip, function, *func_arg):\n",
        "  result_storage = []\n",
        "  for y in range(year_start, year_end + 1):\n",
        "    q_loader_s = 1\n",
        "    q_loader_e = 5\n",
        "    if y == year_start:\n",
        "      q_loader_s = quarter_start\n",
        "    elif y == year_end:\n",
        "      q_loader_e = quarter_end + 1\n",
        "    for q in range(q_loader_s, q_loader_e):\n",
        "      if zip:\n",
        "        curr_coupon_df = load_coupon_df(coupon_path, y, q)\n",
        "        curr_ticket_df = load_ticket_df(ticket_path, y, q)\n",
        "      else:\n",
        "        curr_coupon_df = pd.read_csv(\n",
        "              \"{path_f}/Origin_and_Destination_Survey_DB1BCoupon_{year_f}_{quarter_f}.{file_type}\"\n",
        "              .format(path_f = coupon_path, year_f = y, quarter_f = q, file_type = \"zip\" if zip else \"csv\"))\n",
        "        curr_ticket_df = pd.read_csv(\n",
        "              \"{path_f}/Origin_and_Destination_Survey_DB1BTicket_{year_f}_{quarter_f}.{file_type}\"\n",
        "              .format(path_f = ticket_path, year_f = y, quarter_f = q, file_type = \"zip\" if zip else \"csv\"))\n",
        "      curr_df = gen_ticket_coupon(curr_ticket_df, curr_coupon_df)\n",
        "      del curr_ticket_df\n",
        "      del curr_coupon_df\n",
        "      result_storage.append(function(curr_df, *func_arg))\n",
        "      del curr_df\n",
        "  return result_storage"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grabing race and income bias"
      ],
      "metadata": {
        "id": "osuOWtZLLAni"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPqF4cUDI8f3",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Grabing race and income bias\n",
        "%%writefile graber.py\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# getting lookup table for census data\n",
        "def city_code_reader():\n",
        "  return pd.read_csv(\"https://raw.githubusercontent.com/ptse8204/airlinedatabias/main/lookup/city_id_census.csv\")"
      ]
    }
  ]
}